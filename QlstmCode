QlstmCode:

import tensorflow as tf
import pennylane as qml
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

# Quantum Node definition
dev = qml.device("default.qubit", wires=4)

@qml.qnode(dev, interface="tf")
def quantum_circuit(inputs):
    # Normalize inputs to be in [0, π] range
    inputs = tf.math.sigmoid(inputs) * np.pi
    for i in range(4):
        qml.RX(inputs[i], wires=i)
    # Entangle the qubits
    for i in range(3):
        qml.CNOT(wires=[i, i+1])
    return [qml.expval(qml.PauliZ(i)) for i in range(4)]

# Quantum Feature Map Layer
class QuantumFeatureMap(layers.Layer):
    def __init__(self, output_dim, **kwargs):
        super().__init__(**kwargs)
        self.output_dim = output_dim

    def build(self, input_shape):
        self.kernel = self.add_weight(
            shape=(input_shape[-1], self.output_dim),
            initializer="glorot_uniform",
            name="kernel",
            trainable=True
        )
        self.built = True

    def call(self, inputs):
        projected = tf.matmul(inputs, self.kernel)
        return tf.vectorized_map(quantum_circuit, projected)

# Q-LSTM Layer
class QLSTM(layers.Layer):
    def __init__(self, units, **kwargs):
        super().__init__(**kwargs)
        self.units = units
        self.quantum_feature_map = QuantumFeatureMap(output_dim=4)
        self.lstm_cell = layers.LSTMCell(units)
        self.dense = layers.Dense(1)  # Output 1 value for regression

    def build(self, input_shape):
        # Initialize any layer-specific weights or states here if needed
        super().build(input_shape)  # Required for layer-building process

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        timesteps = tf.shape(inputs)[1]

        # Reshape for quantum processing
        reshaped = tf.reshape(inputs, [-1, inputs.shape[-1]])
        quantum_features = self.quantum_feature_map(reshaped)
        quantum_features = tf.reshape(quantum_features, [batch_size, timesteps, -1])

        # Initialize LSTM state without dtype argument
        initial_state = self.lstm_cell.get_initial_state(batch_size=batch_size)
        state = initial_state

        # Process each timestep dynamically
        outputs = []
        for t in range(tf.shape(quantum_features)[1]):  # Using tf.shape to handle symbolic tensors
            output, state = self.lstm_cell(quantum_features[:, t, :], state)
            outputs.append(output)

        # Stack outputs and apply final dense layer
        lstm_output = tf.stack(outputs, axis=1)
        return self.dense(lstm_output[:, -1, :])  # Return only last output

    def get_config(self):
        config = super().get_config()
        config.update({"units": self.units})
        return config

# Build model
model = models.Sequential([
    layers.Input(shape=(X_train.shape[1], X_train.shape[2])),  # Use Input instead of InputLayer
    QLSTM(units=64),
    layers.Dense(1)
])

model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])

# Training callback to print metrics at the end of each epoch
class PrintMetrics(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print(f"Epoch {epoch+1} - Loss: {logs['loss']:.4f}, MAE: {logs['mean_absolute_error']:.4f}, "
              f"Val Loss: {logs['val_loss']:.4f}, Val MAE: {logs['val_mean_absolute_error']:.4f}")

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[PrintMetrics()],
    verbose=0
)

# Evaluation
y_pred = model.predict(X_test)
y_pred_rescaled = scaler.inverse_transform(y_pred)
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))

mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)
rmse = np.sqrt(mse)

print(f"\nFinal Test Metrics:")
print(f"MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}")

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(y_test_rescaled, label='Actual')
plt.plot(y_pred_rescaled, label='Predicted', alpha=0.7)
plt.title('Solar Radiation Prediction')
plt.xlabel('Time Steps')
plt.ylabel('Radiation')
plt.legend()
plt.show()

# Save the new dataset with the forecasted values
forecasted_data = pd.DataFrame({
    'datetime': pd.date_range(start=solar_radiation_data['datetime'].iloc[-1], periods=25, freq='5T'),
    'predicted_radiation': y_pred_rescaled.flatten()
})

# Save the forecasted data to CSV
forecasted_data.to_csv('forecasted_solar_radiation.csv', index=False)

'/content/forecasted_solar_radiation.csv'  # Path to the saved forecasted dataset


-----------------------------------------------------------------------------------------------


Code-2:

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import pennylane as qml
import matplotlib.pyplot as plt

# Load the solar radiation dataset
solar_radiation_data = pd.read_csv('/content/solar_radiation.csv')

# Merge the date and time columns into a datetime column
solar_radiation_data['datetime'] = pd.to_datetime(solar_radiation_data['9/30/2016'] + ' ' + solar_radiation_data['23:55:18'], format='%m/%d/%Y %H:%M:%S')

# Extract solar radiation data
data = solar_radiation_data['1.27'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Create time-series data
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Set time_step for 24-hour forecasting
time_step = 24
X, y = create_dataset(data_scaled, time_step)

# Reshape X to match LSTM input requirements
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split the data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Quantum Node definition
dev = qml.device("default.qubit", wires=4)

@qml.qnode(dev, interface="tf")
def quantum_circuit(inputs):
    # Normalize inputs to be in [0, π] range
    inputs = tf.math.sigmoid(inputs) * np.pi
    for i in range(4):
        qml.RX(inputs[i], wires=i)
    # Entangle the qubits
    for i in range(3):
        qml.CNOT(wires=[i, i+1])
    return [qml.expval(qml.PauliZ(i)) for i in range(4)]

# Quantum Feature Map Layer
class QuantumFeatureMap(layers.Layer):
    def __init__(self, output_dim, **kwargs):
        super().__init__(**kwargs)
        self.output_dim = output_dim

    def build(self, input_shape):
        self.kernel = self.add_weight(
            shape=(input_shape[-1], self.output_dim),
            initializer="glorot_uniform",
            name="kernel",
            trainable=True
        )
        self.built = True

    def call(self, inputs):
        projected = tf.matmul(inputs, self.kernel)
        return tf.vectorized_map(quantum_circuit, projected)

# Q-LSTM Layer
class QLSTM(layers.Layer):
    def __init__(self, units, **kwargs):
        super().__init__(**kwargs)
        self.units = units
        self.quantum_feature_map = QuantumFeatureMap(output_dim=4)
        self.lstm_cell = layers.LSTMCell(units)
        self.dense = layers.Dense(1)  # Output 1 value for regression

    def build(self, input_shape):
        # Initialize any layer-specific weights or states here if needed
        super().build(input_shape)  # Required for layer-building process

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        timesteps = tf.shape(inputs)[1]

        # Reshape for quantum processing
        reshaped = tf.reshape(inputs, [-1, inputs.shape[-1]])
        quantum_features = self.quantum_feature_map(reshaped)
        quantum_features = tf.reshape(quantum_features, [batch_size, timesteps, -1])

        # Initialize LSTM state without dtype argument
        initial_state = self.lstm_cell.get_initial_state(batch_size=batch_size)
        state = initial_state

        # Process each timestep dynamically
        outputs = []
        for t in range(tf.shape(quantum_features)[1]):
            output, state = self.lstm_cell(quantum_features[:, t, :], state)
            outputs.append(output)

        # Stack outputs and apply final dense layer
        lstm_output = tf.stack(outputs, axis=1)
        return self.dense(lstm_output[:, -1, :])  # Return only last output

    def get_config(self):
        config = super().get_config()
        config.update({"units": self.units})
        return config

# Build model
model = models.Sequential([
    layers.Input(shape=(X_train.shape[1], X_train.shape[2])),  # Input layer
    QLSTM(units=64),
    layers.Dense(1)  # Output layer
])

model.compile(optimizer='adam',
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])

# Training callback
class PrintMetrics(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print(f"Epoch {epoch+1} - Loss: {logs['loss']:.6f}, MAE: {logs['mean_absolute_error']:.6f}, "
              f"Val Loss: {logs['val_loss']:.6f}, Val MAE: {logs['val_mean_absolute_error']:.6f}")

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[PrintMetrics()],
    verbose=0
)

# Evaluation
y_pred = model.predict(X_test)
y_pred_rescaled = scaler.inverse_transform(y_pred)
y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Calculate metrics
mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)
mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)
rmse = np.sqrt(mse)

print(f"\nFinal Test Metrics:")
print(f"MAE: {mae:.6f}, MSE: {mse:.6f}, RMSE: {rmse:.6f}")

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(y_test_rescaled, label='Actual')
plt.plot(y_pred_rescaled, label='Predicted', alpha=0.7)
plt.title('Solar Radiation Prediction')
plt.xlabel('Time Steps')
plt.ylabel('Radiation')
plt.legend()
plt.show()

# Creating a new dataset for forecasting the next 24 hours (with 5-min intervals)
forecast_steps = 288  # 24 hours * 12 (5-min intervals)
forecast_input = data_scaled[-time_step:].reshape(1, time_step, 1)

forecast_output = []
for _ in range(forecast_steps):
    next_value = model.predict(forecast_input)
    forecast_output.append(next_value[0, 0])
    forecast_input = np.append(forecast_input[:, 1:, :], next_value.reshape(1, 1, 1), axis=1)

# Rescale forecasted values
forecast_output_rescaled = scaler.inverse_transform(np.array(forecast_output).reshape(-1, 1))

# Create a new dataset with predicted values
forecast_df = pd.DataFrame(forecast_output_rescaled, columns=['Forecasted Solar Radiation'])
forecast_df['datetime'] = pd.date_range(start=solar_radiation_data['datetime'].iloc[-1], periods=forecast_steps+1, freq='5T')[1:]

# Display the forecasted dataset
import ace_tools as tools; tools.display_dataframe_to_user(name="Forecasted Solar Radiation", dataframe=forecast_df)

Pytorch Code:


import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt

# Load the solar radiation dataset
solar_radiation_data = pd.read_csv('/content/solar_radiation.csv')

# Merge the date and time columns into a datetime column
solar_radiation_data['datetime'] = pd.to_datetime(solar_radiation_data['9/30/2016'] + ' ' + solar_radiation_data['23:55:18'], format='%m/%d/%Y %H:%M:%S')

# Extract solar radiation data
data = solar_radiation_data['1.27'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

# Create time-series data
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Set time_step for 24-hour forecasting
time_step = 24
X, y = create_dataset(data_scaled, time_step)

# Reshape X to match LSTM input requirements
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split the data into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Convert to PyTorch tensors
X_train_tensor = torch.Tensor(X_train)
y_train_tensor = torch.Tensor(y_train)
X_test_tensor = torch.Tensor(X_test)
y_test_tensor = torch.Tensor(y_test)

# Define the Q-LSTM model (Quantum LSTM)
class QLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(QLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(1, x.size(0), hidden_size).to(x.device)
        c0 = torch.zeros(1, x.size(0), hidden_size).to(x.device)
        lstm_out, _ = self.lstm(x, (h0, c0))
        out = self.fc(lstm_out[:, -1, :])  # Use the last time step
        return out.squeeze(-1)  # Remove the extra dimension to match target shape

# Hyperparameters
input_size = 1
hidden_size = 64
output_size = 1
num_epochs = 100
learning_rate = 0.001

# Initialize the model
model = QLSTM(input_size, hidden_size, output_size)

# Loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Ensure the target and prediction shapes match in the loss function
y_train_tensor = y_train_tensor.squeeze(-1)  # Remove the extra dimension for y_train_tensor
y_test_tensor = y_test_tensor.squeeze(-1)    # Same for the test set

# Train the model
best_mae, best_mse, best_rmse = float('inf'), float('inf'), float('inf')
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()
    
    # Forward pass
    y_pred = model(X_train_tensor)
    
    # Compute loss
    loss = criterion(y_pred, y_train_tensor)
    
    # Backward pass and optimization
    loss.backward()
    optimizer.step()
    
    # Evaluate the model
    model.eval()
    y_test_pred = model(X_test_tensor)
    
    # Compute MAE, MSE, RMSE for this epoch
    mae = mean_absolute_error(y_test_tensor.detach().numpy(), y_test_pred.detach().numpy())
    mse = mean_squared_error(y_test_tensor.detach().numpy(), y_test_pred.detach().numpy())
    rmse = np.sqrt(mse)
    
    # Save the best metrics
    if mse < best_mse:
        best_mse = mse
        best_mae = mae
        best_rmse = rmse
    
    # Print metrics for the current epoch
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.6f}, MAE: {mae:.6f}, MSE: {mse:.6f}, RMSE: {rmse:.6f}")

# Print the best metrics at the end
print(f"\nBest Metrics (After {num_epochs} epochs):")
print(f"Best MAE: {best_mae:.6f}, Best MSE: {best_mse:.6f}, Best RMSE: {best_rmse:.6f}")

# Forecast the next 24 hours (5-minute intervals)
forecast_steps = 288  # 24 hours * 12 (5-minute intervals)
forecast_input = torch.Tensor(data_scaled[-time_step:]).reshape(1, time_step, 1)

forecast_output = []
for _ in range(forecast_steps):
    with torch.no_grad():
        next_value = model(forecast_input)
    forecast_output.append(next_value.item())
    forecast_input = torch.cat((forecast_input[:, 1:, :], next_value.unsqueeze(0).unsqueeze(2)), dim=1)

# Rescale forecasted values
forecast_output_rescaled = scaler.inverse_transform(np.array(forecast_output).reshape(-1, 1))

# Create a new dataset with predicted values
forecast_df = pd.DataFrame(forecast_output_rescaled, columns=['Forecasted Solar Radiation'])
forecast_df['datetime'] = pd.date_range(start=solar_radiation_data['datetime'].iloc[-1], periods=forecast_steps+1, freq='5T')[1:]

# Display the forecasted dataset using pandas
import pandas as pd

# Display the forecasted dataset
forecast_df

# Save the forecasted data to a CSV file
forecast_df.to_csv('/content/forecasted_solar_radiation.csv', index=False)

# Notify the user where to download the file
print("The forecasted solar radiation dataset has been saved as 'forecasted_solar_radiation.csv'. You can download it from the link below:")
print("/mnt/data/forecasted_solar_radiation.csv")




